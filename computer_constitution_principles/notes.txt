******************************************************************************
整数的表示
注意    -INT_MIN != INT_MAX
码距    定义编码距离是Hamming Dist.
        则码距定义为合法码的最小距离
奇偶校验
    奇校验      P = D1 xor ... xor Dn xor 1
    偶校验      P = D1 xor ... xor Dn
Hamming code
    {figure hamcode.png}

******************************************************************************
ALU设计

加法
    超前进位
减法
    补码加法
乘法
    原码乘法只讲了累积乘法
    有三种方法.

    补码乘法
        布斯乘法
            {figure buth-mul.png}
            xy = x
                    \times
                 \sum_{i = 0}^{n-1} 2^i (y_{i-1} - y_i)
    补码除法
        直接按照定义, x / y = sgn(x/y) |x| / |y|

******************************************************************************
浮点数

计算机表示基本结构是
        S       E       M
按照 IEEE 754, 各个域的长度是
    float:  S: 1, E: 8,  M: 23
    double: S: 1, E: 11, M: 52

1. Normalized
    要求
        E 不是全0, 不是全1
    - E' = E - bias
        bias = 2**(LE-1) - 1
    - S' = S==0 ? 1 : -1
    - val =
        S' * (1.M)* 2**E'

    e.g.::
        S   E           M
        0   0111 1101   101 0110 0000 0000 0000 0000
    * 1.M         = 1.101011
    * E'          = -(0111 1111 - 0111 1101) = -10 = -2
    * 1.M * 2**E' = .01 10 1011
    * S'          = +1
    * val         = 107 / 256

2. Denormalized
    要求
        E 是全 0
    - S' = S==0 ? 1 : -1
    - E' = -bias + 1
        bias = 2**(LE-1) - 1
    - val =
        S' * (0.M)* 2**E'

    e.g. (float8, 1/4/3)
        S   E   M
        0 0000 010
    * val = 1 / 256

3. Special
    要求
        E 是全 1
    - 如果M == 0, 表示inf (注意区分±inf)
    - 如果M != 0, 表示nan, 如 0./0. 或者 sqrt(-4.)

浮点加法
    (1/3/7)
    {3: 阶码用4位移码（含符号位）
     7: 尾数用8位原码（含符号位）
     -> 计算的时候, 4}
    X =   2^1 x 1.101111
    Y = - 2^3 × 1.010110
    按照指数大的对齐
    X =   2^3 x 0.011011 11[truncated]
    Y = - 2^3 x 1.010110
    X + Y =
        - 2^4 x 0.111011

******************************************************************************
ctrl
    指令系统
        处在硬件系统和软件系统之间, 是硬; 软件之间的接口部分
        CISC
            条数多, 格式多, 寻址多
            指令并行度差
            例子如
                Pentium
        RISC
            条数少, 格式规整
            指令并行度好
            例子如
                MIPS    (主要就3种寻址方式)

    指令表示
        指令中的内容,
            1. 指令操作码 opcode
            2. 操作数或指令的地址（指明用到的数据或地址） oprnd
                寄存器编号
                设备端口地址，
                存储器的单元地址
                立即数值

    指令字长
        一条指令的位数
        - 定长指令字结构
        - 变长指令字结构
    指令操作码扩展技术
        允许操作码长度不同, 如允许4位, 8位, 12位等等
            e.g. 16位指令, 一个地址码段4位
            16条    3地址指令   (这里3地址就是3目指令的意思)
            256条   2地址指令   (同上, 和主存地址没有关系)
            ...
        然后做一些escaping,
        如4位操作码是1111表示这应当为一条8位操作码,
            8位操作码是1111 1111表示这应当为一条12位操作码

    寻址方式
        确定本条指令的操作数地址
        及下一条要执行的指令地址的方法
        注意这里的地址不一定是内存地址
        - 立即数寻址    指令中给出立即数作为算数
        - 直接寻址      指令中给出立即数作为算数的主存地址
        - 寄存器寻址    指令中指定寄存器作为算数
        - 变址寻址      相当于 offset(rt)
        - 相对寻址      给出相对于PC的地址
        - 间接寻址      指令中给出主存地址, 作为算数的主存地址的指针
                                                        (的指针的...)
        - 基址寻址      给出相对于GP的地址
        - 堆栈寻址      push / pop 指令
******************************************************************************
CPU设计
    在某些计算机中将一个周期更加细分为多个节拍
    对于 IF/ID/EX/MEM/WB 五阶段的处理器
        单周期串行 CPU: CPI =     1
        多周期串行 CPU: CPI \sim  4
        流水线 CPU:     尖峰CPI = 1

D触发器在就是上升沿触发器
PC 一般指的是 IF阶段的指令地址

单周期CPU
    一条语句占用一个周期
    - 逻辑时序设计简单
    - 各个部件利用率低
    - 时钟周期需要满足最长时间的指令

多周期CPU
    每个阶段占用一个周期, 周期可以变短
    需要一个控制器, 控制指令的执行, 给系统部件发送控制信号
    分为
        - 硬连线控制器 (组合逻辑控制器)
            组成:
                1. 程序计数器PC
                2. 指令寄存器IR
                    保存读取到的指令内容
                3. 节拍发生器Timer
                    给出指令执行到哪个阶段
                4. 控制信号产生部件
                    根据PC和IR给出控制信号
        - 微程序控制器
            使用一个存储器存储每条指令每个步骤的控制信号
            指令操作码给出第1条微指令的地址
                之后每条微指令给出下一条的地址
    对于MIPS指令集
        jxx指令可2步完成 (IF, ID 之后立刻跳转)
        bxx指令可3步完成 (IF, ID 之后 ALU)
        r型指令可4步完成 (IF, ID, ALU, WB)
        store指令可4步完成 (IF, ID, ALU, MEM)
        load指令可5步完成 (IF, ID, ALU, MEM, WB)
    通常控制器采用状态机设计

流水线CPU
    原理为并行重叠执行
    每个阶段后面有一个锁存器用来同步
        (流水线寄存器 / 流水线锁存器)
    流水线寄存器保存着
        <从一个流水段传送到下一个流水段的>
        所有数据和控制信号
    要求
        - 流水线时钟周期不能快于最慢的流水段
        - 在流水线中处理的必须是连续任务
        - 流水线有装入时间 (第一个任务进入流水线到执行完成的时间)
            和排空时间 (最后一个任务从进入流水线到执行完成的时间)
            这期间流水线是没有完全运行的
    分类
        - 部件功能级流水线
            操作运算流水线
            &. 浮点加法器
        - 处理机级流水线
            指令流水线
        - 处理机间级流水线
            宏流水线
            连接多个处理机
    衡量指标
        - 加速比
            与串行执行时速度提高的比率
        - 吞吐率
            单位时间执行指令的数量

    多周期CPU不适合流水线, 因为阶段不规整容易冲突
    流水线阶段都很规整 (IF..WB 一个不多一个不少)

    各个阶段相关的部件
        阶段    相关部件
        IF:    IMEM     ; PC                ; 总线
        ID/RF: 寄存器组 ; 控制信号生成部件
        EXE:   ALU
        MEM:   DMEM     ; 总线
        WB:    寄存器组

    MIPS指令系统适用于流水线的原因
        - 指令定长
            ID 可以在 IF 之后完成,
            否则需要在 IF 阶段完成 ID 从而得到指令长度并且传递给 PC
            又增加了IF阶段的长度
        - 指令格式
            可以早在 ID 阶段就读寄存器
        - 访存方式
            只有load/store, 流水线阶段中只有一个 MEM 放在 EX 后面
            否则如果算数在内存中, 还需要在 EX 前访存得到算数
        - 数据对齐
            一次访问一个字

    冲突
        资源冲突
            MEM 和 IF 冲突
        数据冲突
            WB 前使用
        转移地址
            难道在 EX 阶段计算

    冲突分类
        - 结构冲突
            硬件资源满足不了指令重叠执行的要求
            e.g. 存储只有一个读口, MEM / IF 冲突
        - 数据冲突
            重叠执行的指令有数据依赖不能满足
            e.g. load / use, forwarding
        - 控制冲突
            需要改写PC的指令造成的冲突
            e.g. 跳转地址提前到ID段计算, delay slot

******************************************************************************
冲突解决

解决冲突通用
    暂停 (气泡)
    效率损失太大

结构冲突
    基本方法是增加资源
    如设置双口存储器, 取指令和访问数据可以并行进行

数据冲突
    分为
    - RAW 写后读冲突
        解决:
            1. 旁路方法, 又称转发, 前推
                - just-load RAW
                    读寄存器的指令必须暂停一个周期
                - 其他 RAW
                    EX阶段就可以确定写的值, 可以直接转发不用暂停
            2. 编译器调度 (静态调度)
                通过编译器改变汇编语句的顺序, 来避免冲突
                e.g. 无冲突的 memcpy
            3. 处理器乱序发射 (动态调度)
                基本思想:
                    指令顺序发射, 乱序执行, 指令乱序流出
                问题:   难以实现精确异常
    - WAW 写后写冲突
        表现: 后面的语句比前面的语句先写资源
        原因: 允许多个流水线阶段写寄存器 / 允许语句暂停时后面的语句不暂停
        MIPS 不会发生 WAW 冲突
    - WAR
        MIPS 不会发生 WAR 冲突

控制冲突
    所有指令都要在 IF 阶段使用 PC 来读取指令,
        但是对于 bxx 指令, 需要到 EX 阶段才能确定 PC值;
            对于 jxx 是在 ID 阶段
    1. 暂停流水线, 直到计算出 PC
        效率低
    * 提前判断和计算:
        在 ID 阶段就判断是否转移并且计算转移地址
    2. 分支预测
        - always-taken
            总是预测转移
        - never-taken
            总是预测不转移
        - take-previous
            硬件记忆上一次是否转移, 本次相同
            Branch Target Buffer (BTB):
                如图是带动态预测的BTB,
                {figure btb.png}
                对于转移指令保存其是否跳转, 以及跳转地址
                之后在 IF 阶段通过 BTB 就可以获取下条PC
            动态预测能够有效提高预测准确率
            变种有多位动态预测, 如当连续猜错2次才更改预测方向
                对于多重循环有效
        分支预测失败: 需要清除已经执行的语句的副作用
    3. 延迟槽
        无论是否跳转, 跳转指令后续n条指令都要执行
        填充延迟槽
            - 手动bubble
            - 来自延迟槽前的语句
                分支语句不能依赖这条语句
                总提高流水线性能
            - 来自跳转成功/失败地址的指令
                需要保证没有影响
                跳转成功/失败时提高流水线性能

异常
    中断程序正常执行流程的事件
    - 异常      来自 CPU
    - 中断      来自外部
    * 精确异常处理
        EPC中保存exception victim
        操作系统处理简单
        指令流水情况下实现比较复杂
    * 非精确异常处理
        EPC中保存当前PC或者近似的PC
        由操作系统处理

******************************************************************************
dram    1个晶体管, 1个电容
        读完就变成0, 内部控制电路需要完成回写
        需要刷新
sram    6个晶体管

+------------------------------+
|            | dram   | sram   |
| 存储介质   | 电容   | 触发器 |
| 破坏性读取 | 是     | 否     |
| 需要刷新   | 是     | 否     |
| 送行列地址 | 两次送 | 一次送 |
| 运行速度   | 慢     | 快     |
| 集成度     | 高     | 低     |
| 发热量     | 小     | 大     |
| 成本       | 低     | 高     |
+------------------------------+

程序的局部性原理
    顺序: 更可能顺序访问而非随机访问
    时间: 此时访问, 将来访问
    空间: 此处访问, 周围访问
    -> 利用层次存储器

cache   主存和CPU之间
    特点
        高速    基本匹配 CPU 的速度
            (事实上从 L1 取值, 因此需要 L1 不比 CPU 时钟慢)
        透明    完全硬件管理, 对程序员透明

    cache结构
        一个cache line
            +---------+-------------+---------------+---------------+   +--------------+
            |  VALID  |     TAG     | DATA 0        | DATA 1        |...| DATA k       |
            +---------+-------------+---------------+---------------+   +--------------+
            其中
                VALID: cache 是否有效 e.g. 刚刚开机时, cache一定无效
                TAG: 因为一个块可能是多个内存区域的缓存, TAG
                    用来表示其缓存的是哪一块内存
                DATA: 缓存的数据, DATA 0等常常为 32 位字
            缓存命中条件是 VALID, 而且 TAG 比对成功
        cache 和主存都监听地址总线, 都向数据总线发送数据

    问题
        1. 通过内存地址得到cache中的数据
            检查TAG 和VALID
        2. 主存-cache的数据一致性
            -> esp. 多核cpu, 不同cpu cache间的情况
        3. 数据交换粒度
            就是一个cache line
            每次数据装载的最小单位就是块
        4. cache的内容装载和替换策略
            提高命中率HR = 命中次数 / 访问次数

    参数
        块 (line)       数据交换的最小粒度
            e.g.    4~128 B
        命中            在较高层次的存储 (靠近cpu) 中发现内容
        命中率          ...
            e.g.    80~99 %
        命中时间        访问较高层次的存储 (靠近cpu) 中内容用时
            e.g.    1~4 cyc
        不命中代价      ...
            e.g. 10~50 cyc
        平均访问时间
            命中率 * 命中时间 + 不命中率 * 不命中代价
            提高效率: 提高命中率; 减小不命中代价; 提高命中时间

    cache装载策略
        全相联
            主存中任何地址可以装入cache中任何地址
            31                                                      0
            +------------------------------------------+-------------+
            |  TAG                                     | last 2 bit  |
            +------------------------------------------+-------------+
            一个cache line大小为1个记录
            TAG = ADDR(31 downto 2)
            写入cache
                先检查是否已经在cache中
                如果有空cache line, 直接装入该cache line
                否则按照替换策略, 选择一个cache line替换
                替换策略有
                    LRU     较高命中率, 但复杂
                    FIFO    满足局部性, 较简单
                    RAND    命中率也行, 较简单
            读取cache
                按照标记, 做一个 N路选择器
                N是cache line的数目, 常常达到1024
            特点
                利用率高, 灵活
                TAG太宽     代价太高
                N路选择器   代价太高
            主要使用在TLB, 内存对于磁盘的缓存等

        直接映射
            主存中地址ADDR是如下关系
            31                                                      0
            +------------+-----------+-----------------+-------------+
            |  TAG       | INDEX     | OFFSET          | last 2 bit  |
            +------------+-----------+-----------------+-------------+
            有 2 ** sizeof(INDEX) 个 cache line
            一个cache line可能有 2 ** sizeof(OFFSET) 个记录
            INDEX表示ADDR应存放到哪个cache line中
            TAG用来比较确定该cache line中确实存放了ADDR周围的数据
            OFFSET用来确定ADDR在对应的cache line中是哪一个记录
            写入cache
                先检查是否已经在 (INDEX中TAG相等)
                将TAG改写, 然后写入块大小个记录
            读取cache
                直接按照TAG, INDEX, OFFSET来即可
            特点
                提高块大小可以提高空间局部性, 但是装载代价太大
                    (当然也要受限于访问特性)
                方式直接, 但利用率低
                标志位短
                只需要比较一次 (只需要比较一个cache line的TAG)

        组相联
            主存中地址ADDR是如下关系
            31                                                      0
            +------------+-----------+-----------------+-------------+
            |  TAG       | INDEX     | OFFSET          | last 2 bit  |
            +------------+-----------+-----------------+-------------+
            此ADDR映射到块号为 ('0...0' . INDEX) - ('1...1' . INDEX)
            有 2 ** (sizeof(INDEX) + k) 个cache line, 称 2**k 路组相联
            一个cache line可能有2 ** sizeof(OFFSET) 个记录
            可以看成是 2**k 个直接映射组成的全相联
            效率成本取得均衡, 是常用的方式

        可以看成如下结构
            每个内存单元被唯一映射到某一行,
            但其可以选择该行中任意一列
            全相联
                +-------------------+-------------------+-------------------+-------------------+
                | VALID, TAG, DATA  | VALID, TAG, DATA  | VALID, TAG, DATA  | VALID, TAG, DATA  |
                +-------------------+-------------------+-------------------+-------------------+
            组相联
                +-------------------+-------------------+
                | VALID, TAG, DATA  | VALID, TAG, DATA  |
                +-------------------+-------------------+
                | VALID, TAG, DATA  | VALID, TAG, DATA  |
                +-------------------+-------------------+
                | VALID, TAG, DATA  | VALID, TAG, DATA  |
                +-------------------+-------------------+
                | VALID, TAG, DATA  | VALID, TAG, DATA  |
                +-------------------+-------------------+
            直接映射
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
                | VALID, TAG, DATA  |
                +-------------------+
        装载全相联和组相联时,
            需要按照一定算法 (RAND; FIFO; LRU),
            决定装入哪一列

    一致性保证
        直写
            强力保证一致性, 效率低
            写操作
                在cache中命中:
                    同时写cache和内存
                在cache中不命中:
                    写内存
                    装载/不装载入cache
        回写
            弱一致性保证, 替换cache时再写主存
            写操作
                在cache中命中:
                    写cache, 标记cache为DIRTY
                在cache中不命中:
                    装载cache + 写cache
            替换cache line操作
                如果cache line为DIRTY, 将其写到内存中
            注意可能需要监听内存总线, 如果有外部修改内存发生
                如多核CPU等
            减少写内存次数, 效率高

    缓存不命中原因
        compulsory miss
            由于冷缓存
            解决: prefetch等
        capacity miss
            活动数据集大小大于缓存大小
            解决: 增大缓存容量
        conflict miss
            由于冲突 (INDEX相等, TAG不同)
            解决: 增加相联组数
        invalidated miss
            其他进程修改了主存数据等

    变种
        多级cache
            exclusive   L2进入L1时, L2中的数据失效
            inclusive   L2中数据保持 似乎课程采用这个
        哈弗结构cache (L1实际应用)
            L1 D-cache; L1 I-cache;
        cache接入系统
            - 直接接系统总线, 成本低
            - 特别总线连到cpu, 系统总线连到内存, 成本高
        MESI一致性保证
            在多级 cache 中的一致性, 以及 cache 和主存的一致性
            MESI: 一个cache line可能的4种状态
                Modified:
                    块只在当前 cache 中, 且被修改
                    i.e. 当前 cache 中的才是正确值; 主存中数据过时)
                    未来应当被回写的块
                Exclusive:
                    块只在当前 cache 中, 未被修改
                    i.e. 块和主存是一致的
                Shared:
                    块可能在机器中其他 cache 中, 但是未被修改
                    i.e. 和内存是一致的
                Invalid:
                    块无效
            制定了一系列的转移规则, 包括 CPU 和总线事务的处理

******************************************************************************
虚拟内存
    只有在确实需要的时候才将数据和程序装载入主存
    好处
        - 隔离进程地址空间, 隔离进程和操作系统
        - 实现物理内存的共享
            i.e. 标准例程的 text 在物理内存中只有一块
        - 实现内存保护, i.e. 读写权限控制
        - (可能有问题) 提供更大的地址空间
    cache中, 可能是虚拟地址, 可能是物理地址

虚拟存储器管理
    完成虚拟地址和物理地址的转换
        并且控制数据调度, 尽量提高命中率 etc

段地址转换
    以段 (segment) 作为存储保护的对象

    将虚拟地址分成:
        +-------------+-------------------+-------+
        | 段号        | 段内地址          | 末尾0 |
        +-------------+-------------------+-------+
        段号: 这个虚拟地址属于哪一段
        段内地址: 段内偏移量

    段表
        段表在内存中其地址由段表基地址寄存器给出
        段表每个条目如
            +-----------+--------------+-------------+
            | 段始地址  | 段长         | 装入位      |
            +-----------+--------------+-------------+
            段始地址: 该段在物理内存中的位置
            段长:     可变; 但是x86中确定不变
            装入位:   段是否装入内存 i.e. 虚拟地址是否对应物理地址
            其他标记: 段保护 (可读可写?), 进程间共享等
        虚拟地址段号长为L, 则段表有 2**L 个条目

    地址翻译
          +------------*虚拟地址----->偏移量-----+
          |                                      |
          |                                      v
          v      .--.                           .--.
        段号-----|加|--->段条目---->段始地址----|加|--->物理地址
                 .--.                           .--.
                  ^
                  |
              段表基地址

    特点
        容易实现共享和保护
        容易产生碎片, 因为段长可变

页式地址转换
    将物理内存和虚拟内存分划成固定大小的页
    利用内存中页表将虚拟页映射到物理页 (页内偏移不变)

    页表表项
        +---------------+--------+--------+
        | 物理页页号    | 有效位 | 控制位 |
        +---------------+--------+--------+

    虚拟地址构成
        +--------------+---------------+
        | 虚拟页页号   | 页内偏移      |
        +--------------+---------------+
        虚拟页页号: 用于索引页表表项
        页内偏移:   加上物理页页号就是物理地址

    交换相关
        如果页不在内存中, 但是的确有效
        需要操作系统将其装入内存 e.g. 从磁盘中读取

    问题:
        页表巨大 (注意页表大小和页大小是不同的概念)
            如果页大小为2**12字节 (4K)
            那么对于32位内存, 需要有 1M 个页项,
            就是 4M 内存
            -> 早期32位机器只有 128 MB 内存甚至更少
                4M 的页表相当于今天的 (4G内存) 中 128M 的页表

    页大小选择
        越小:   内存浪费越少, 碎片越少, 页表页目录越大
        越大:   转换速度越快 (极端情况就一个页项, 直接恒等变换)
                因为查页表是PageFault, 软件实现的,
                    需要迭代查找所有的页项, 因此页项越少越好
        目前页大小一般为 4K

层次页式转换
    维护多个页表, 页表也可以是'无效'的 i.e. 该页表不在内存中存储

    虚拟地址构成
        +--------------+----------------+------------------+
        | 页表号       | 页表内页号     | 页内偏移量       |
        +--------------+----------------+------------------+
        页表号: 从页表目录中索引页表, 得到页表地址
        页表内页号: 从页表中索引页, 得到页地址
        页内偏移量: 加上页地址就是物理地址
    如图所示
        页表号 ---+----> 页 ----+----> 起始地址 -----+----> 物理地址
                  |             |                    |
                  |             |                    |
                页目录        页内偏移量          内存偏移量

    页表可以被创建 i.e. 没有用过的页表号, 其对应页表不存在

    改进:
        假设分割是 10, 10, 12
        页目录大小: 4K
        每个页表大小: 4K
        即使程序使用了50个页表, 也只是 204K, 是 4M 的 5%

TLB
    - 对页表的访问非常频繁: 每次访存都完成虚实转换
    - 页表存储在主存中, 主存很慢
    将页项缓存入TLB, 称 "快表"
        可以理解 TLB 就是一个很快的小页表
        对应称内存中页表为 "慢表"

    TLB一项的基础结构
        +------------------+------------------+
        | 虚页号           | 实页号           |
        +------------------+------------------+
        (TLB一定有效且在内存中; 至于控制位, ASID等可以加)

    TLB缺失的流程 (MIPS 软件处理快表缺失)
        - 流水线停止 (TLB Miss 异常)
        - 通知操作系统
        - 读页表
        - 将表项写入 TLB
        - 返回用户程序
        - 重新执行访存指令

    TLB缺失代价很大, 需要尽力降低冲突
        TLB 实现为全相联
        (中档计算机中可能为了节省成本实现组相联)

    原访存流程:
        虚页号 -(慢表)-> 实页号 -> 地址
    现在访存流程
        虚页号 -(TLB)->
            TLB中找到 -> 实页号 -> 地址
            TLB中没找到 -(慢表)->
                页在内存中
                    得到实页号 -> 地址
                    修改TLB
                页不在内存中, 有效
                    PageFault, 调用Handler
                页无效
                    出错崩溃

    PageFault Handler
        CPU访问辅存 ->
            主存满
                执行页面替换,
                    选择主存中一页写入辅存 -> 修改页表 [此页在内存中,
                    将此页面装入内存                    某页不在内存中]
            主存有空
                直接装入内存 -> 修改页表 [此页在内存中]

    页表替换算法
        因为空间 etc 有时需要将某些页存入内存
        选择存入页的算法
        LRU
            每次访问一个页, 页就放到页表开头
            这样页表结尾就是最近最少访问的项, 替换它即可

    段页式
        先做段转换, 之后在进行二层页转换

******************************************************************************
磁表面存储
磁芯, 磁记录方式: 显然不考 (陈康)
    磁表面存储设备
        磁颗粒中偏转方向
        随机读取
            访问时间与信息存放的位置无关
            每一位都有各自的读写设备
        串行访问
            访问时间和存储位置有关

    主要技术指标
        存储密度 / 容量
        寻址时间
        带宽
        价格

    硬盘结构
        多片 (platter) 重叠
        每片有多个同心圆, 称道 (track)
        每道分为多个扇区 (sector)
        柱面 (cylinder) 多片上同一个道

        扇区是访问的最小单位
        外层道可以包含更多的扇区, 现代硬盘外道扇区数更多
        一般扇区大小较小
            - 出错时直接抛弃扇区
            - 每个扇区有检错, 小扇区有利检错
            - 灵活性: 扇区比页大就不好了
        可以并行读多个片

        页应当保存在相邻的扇区中, 避免额外的寻道和寻扇区开销

    访问过程
        寻道        典型时间 8 ~ 12 ms
        寻扇区      时间 平均一半周转时间
        读写数据    数据数据 / 传输速度

    访问磁盘总是由于缺页造成的 (MIPS中, 磁盘映射到内存位置)

    RAID技术
        目标: 提高可用性和性能
        RAID0
            提高访问速度
            将虚拟磁盘分划为多个带 (strip),
                相邻带分布在不同磁盘上, 可以并行读取
             disk 1     disk 2
           +--------+ +--------+
           | S0     | | S1     |
           +--------+ +--------+
           | S2     | | S3     |
           +--------+ +--------+
           | S4     | | S5     |
           +--------+ +--------+
           | S6     | | S6     |
           +--------+ +--------+
            不是真的RAID (不R), 没有冗余, 可靠性差
        RAID1
            两个RAID 0
            写性能不高, 读性能提高一倍
            成本高
        RAID2
            e.g. 存储分为4个位, 4个位 (半字节) 的
            采用Hamming码, 用7个位来存4个位
            这样有 7 个同步旋转的磁盘,
            一次读得到一个半字节 (Hamming Code表示) 的信息
        RAID3
            e.g. D1, D2, D3是数据盘, D4是校验盘
            驱动器需要严格同步
            能够恢复整个磁盘的崩溃
        RAID4
            将校验数据存在另一个单独的盘上
            可以防止整个盘崩溃, 但是难以解决盘上部分字节出错
            校验盘负载重
        RAID5
            将RAID4的校验分散
        RAID6


******************************************************************************
wk13 MIPS异常处理
    异常和中断
        异常    CPU内部, 是执行某条指令的结果
        中断    CPU外部, 发生的时机不可预测

    CP0
        处理器 / 硬件控制等信息
        IE:       -> 异常处理过程中不允许中断
        IM[8]:    中断屏蔽
        EXL:      异常级别, 进入内核态, 禁止中断
        KSU:      内核, 用户等模式
        ebase:    ebase[n] 存储n号异常处理程序的入口
        BadVAddr: 访存出错的虚拟地址

    流水CPU
        精确异常
            产生异常时, victim之前的指令都执行完成
                        victim及以后的指令都如同没有执行
        如果是异常, EPC 就是 exception victim
            如果是延迟槽中指令引发异常, EPC = (victim)PC - 4
            否则 EPC = (victim)PC

    异常分类
        - 外部中断
        - 访存异常
        - 系统调用
        - 计算异常
        - 程序/硬件错误

    异常和终端处理流程
        检测
            设置Cause寄存器
        响应
            保留断点: EPC STATUS
        处理
            保存现场: GPR
            执行服务程序
        返回
            返回断点, 继续执行 
    　
    异常处理的流程
        保存现场
            保存如 k0, k1
        判断异常类型, 跳转到处理程序
            通过查询 cause
        构造异常处理内存空间
            这一步才保存GPR到栈上,
        处理异常
        恢复原程序
            恢复 GPR, 恢复 SR

    异常返回
        使用eret来同时完成设置用户态和跳转

    中断处理
        是处理器外设的信号
        中断发生时, 完成 MEM 阶段的指令继续执行, 其他指令丢弃
        因为修改处理器/计算机状态的阶段只有 MEM/WB

    启动过程
        SI_ColdReset 信号
        处理器执行完全的复位初始化
        从 PC = BFC0 0000 (unmapped, uncached) 开始执行

    异常嵌套
        异常处理的时候允许发生另一个异常
        - 异常处理过程中, 被中断的程序的关键信息存放在 EPC, SR, CAUSE 等
            另一个异常会改写这些寄存器
            需要保存这些寄存器
        - 可能也要保存 k0, k1的值
        利用异常帧, 将异常处理状态存入主存
        异常帧消耗资源, 因此限制异常嵌套深度
            e.g. 异常有优先级, 某优先级异常被服务时,
            只有严格更高优先级的异常才能发生

    虚拟地址划分
        32位虚拟地址
        0000 0000 ~ 7FFF FFFF | 2G   | KUSEG | mapped, user space
        8000 0000 ~ 9FFF FFFF | 512M | KSEG0 | unmapped cached
        A000 0000 ~ BFFF FFFF | 512M | KSEG1 | unmapped uncached
        C000 0000 ~ FFFF FFFF | 1G   | KSEG2 | mapped, kernel space

        任何处理器的访存都需要经过 MMU 的转换

    TLB 设计
        TLB 需要包含 VPN, ASID, PFN, 以及标记
        通过 CP0 的寄存器
            PageMask:           用于页大小大于 4KB 的项
            Index:              写哪一个TLB
            EntryHi:            VPN / ASID
            EntryLo0, EntryLo1: PFN, Access Priviledge
            Random:             如果需要随机替换 TLB, 使用这个
            Context, XContext:  加速TLB refill
    TLB 维护
        ITLB 和 DTLB: 完全硬件维护, 对软件透明
        JTLB (joint TLB) 维护:
            通过 TLBWI 和 TLBWR 写 TLB
            填充 TLB 前, 先更新相关的 CP0 寄存器
    TLB 异常处理
        [假设存储使用了TLB]
        没有匹配的 TLB (vpn, asid), 或者匹配但是合法指示位无效
            并且 SR(EXL) = 1
        虚存地址大于等于固定映射存储管理器的上界


******************************************************************************
I/O
    外设输入输出性质
        数据传输速率差异很大

    I/O方式
        CPU控制输入输出的方式
        基本外设控制方式: 通过外设寄存器

        程序直接控制
            需要轮询
            直接映射到一个地址, 通过MMU解决
            通过类似 x86 的 in, out 指令
            特点
                - 成本低
                - 效率低
                - 耗费CPU资源
            适用于早期计算机中高速设备

        程序中断
            处理速度较轮询慢
            仅当外部设备请求时, CPU才响应
            步骤
                - 外设发起请求
                    外设设置中断控制器
                - 处理器暂停正在处理的程序, 响应外设请求
                    MEM, WB指令继续执行, 其余 bubble 掉
                    保存现场, 处理中断, 中断返回
                - 处理完成后, 处理器恢复执行原程序
                注意嵌套中断
            控制
                关中断
                保存断点
                判断中断类型, 转中断处理服务
                开中断
                执行中断服务
                关中断
                恢复断点
                开中断
                返回断点
            8259A
                一片芯片只有8个中断源
                两片共15个中断源
                但是可以接总线, 一个中断源对应多个外设
            适用于 传输速度不高, 传输量不大的情况
            对 CPU 打扰大

        DMA
            IO设备和主存间的直接数据通路
                用于在高速IO设备和主存间成组传输数据
            工作方式
                - 独占总线方式
                    IO设备需要使用内存总线时,
                    DMA发送控制信号给CPU
                    传输完成再通知CPU可以使用总线
                - 周期窃取方式
                    一旦IO设备有DMA请求, 则IO设备挪用若干周期
                    IO设备访问主存的优先级高于CPU
                - 和CPU交替访存
                    1个CPU周期分2部分, 1部分CPU访存, 1部分DMA访存
                确定DMA设备如何和主存通信,
                    是一段周期内独占总线和主存通信
                    还是窃取周期和主存通信
            传输过程
                - 预处理
                    CPU 将内存起始地址; 设备地址;
                        数据传输个数送给DMA
                    之后启动设备
                - 数据传送
                    继续执行主程序,
                    同时完成一批数据传输
                - 后处理
                    中断服务程序执行DMA结束处理
            允许设备直接访问内存
            适用于告诉设备
            问题
                虚实地址控制
                    DMA 采用实地址: 虚拟地址是否连续
                    DMA 采用虚地址: DMA 需要实现虚实转换
                    一般使用实 (物理) 地址
                Cache一致性
                    - 不缓存
                    - DMA检查cache, 允许DMA访问cache
            特点
                一个DMA对应一个外设
                多个DMA 同时工作可能产生冲突
            对 CPU 打扰中等
            不适用于大量高速设备的管理

        通道控制
            代替CPU, 管理控制外设的独立部件
            能执行有限I/O指令 (通道命令) 的I/O处理机

            - 和外设通信, 根据 CPU 要求, 像外设发出初始化等命令
            - 告诉外设读写信息的地址, 访问主存的缓冲区地址
            - 控制外设与主存之间的数据交换

            类型
                - 字节多路通道
                    简单的共享通道，分时处理，面向低、中速字符设备
                - 选择通道
                    选择一台外设独占整个通道，以成组传送方式传送数据块，效率高，适合快速设备
                - 数组多路通道
                    上两种方式的结合，效率高，控制复杂

        外围处理机
            通道控制是和主机共享内存
            外围处理机是一台独立的计算机,
                独立完成IO功能, 通过通道方式和主机交互

******************************************************************************
wk14
    总线
        基本概念
            共享的信息通道
            用于连接计算机多个子系统
        好处
            - 增加减少设备简单
            - 降低成本
            - 简化设计
        不足
            - 容易成为效率瓶颈

        只要实现 PCI 电气特点, 就可接入总线
        多个设备共享总线 (但是每时每刻只能有一个设备可用)
        特点
            外设接口标准化
            成为外设速度瓶颈
                被最慢的外设拖累

    例子
        单总线计算机
            使用一条总线, 完成 CPU 和 主存, 外设间的通信
            早期计算机
            简单, 成本低, 但是速度慢
        双总线
            有一条处理器-主存总线,
                I/O 总线通过适配器和 Memory 总线相连
        三总线
            I/O 总线通过适配器连到 主板 PCI/PCIE 总线
            主板 PCI/PCIE 通过适配器连到 Memory 总线

    类型
        处理器-主存 [专用]
            距离短速度高, 需要保证 CPU 和主存间的高带宽
            在内存和 (也要包括片外cache) 中快速传输数据
        I/O 总线 [行业标准]
            通常距离长速度慢, 但是适应多种IO设备
            通过桥 / 主板和处理器-主存总线相连
        主板总线 [都有]
            支持CPU和主存两者与外部设备连接

    组成
        --------------------------------------------- 控制线
        --------------------------------------------- 数据线
        控制线: 总线请求信号及数据接收信号
        数据线: 传送信息 (数据和地址, 以及复杂的命令)
        数据线一般包含数据和地址

    主设备  控制总线, 发起总线事务, 常常为CPU
    从设备  响应总线事务
    异步控制    通过控制信号
    同步设备    线上所有设备使用同一个时钟

    永远是主设备发起传输动作 (总线事务)
        数据线是双向的
    如果主设备被设计为只有 CPU, 那么不会有总线冲突
        但是 CPU 负担太重

    多个主设备
        仲裁
            主设备使用前先发出总线请求
            得到授权才能使用总线
        要求    - 优先级
                - 公平性
        实际    - 集中仲裁 类似一个超级主设备
                - 分布总裁 类似网路 MAC 访问
        菊链设备
            request 共用一条线发给仲裁者
            仲裁者给 最高优先级 允许使用的令牌
            最高优先级开始, 向下传递令牌
        集中平行仲裁
            总线仲裁器接受所有主设备的请求,
                向所有主设备发送授权与否
            几乎用于所有处理器主存总线和一些高速输入输出总线
        分布仲裁
            每个要使用总线的设备在总线上放上自己的标志
            类似 ethernet

    同步总线
        控制线中包含时钟
        传输协议按照时钟制定
        优点
            - 简单, 高速
        缺点
            - 总线不能太长, 否则时钟扭曲
            - 总线上所有设备都需要按照此时钟频率工作

    异步总线
        可以适应不同的设备速度
        距离可以较长, 不用考虑时钟扭曲
        使用握手协议

    优化带宽
        - 增加总线宽度 (不过现在多用串行, 更快)
        - 采用成组传输, 一个总线事务传输多个数据
            只需要最开始的一次给一个地址, 之后顺序传输
        - 当前事务时, 为下一事务仲裁
        - 总线占用, 除非有其他主设备申请总线, 否则某主设备一直占用总线

简单同步协议图似有误

******************************************************************************
接口电路和外部设备
输入输出系统
    接口
        - [连接外部设备 / 设备识别]
            提供主机识别外设的方式
            e.g. 为外设提供编码
        - [协议实现]
            提供主机和外设控制通信的机制
        - [数据缓冲]
            提供主机和外设信息交换的缓冲
        - 其他需求 e.g. 统一化外设
            * [屏蔽差异]
            * [通过总线与主机进行通信]

    8251 串行接口
        可以同步或者异步
        同步    采用同步信号
            内同步: 同步字符
            外同步: 硬件同步信号
        异步    采用 RDY 信号和 ACK 信号
            波特率: 就是每秒传输多少个字,
                乘以一个字的长度就是比特率
        完成全双工:
            一条数据线不能完成全双工
            两条数据线, 通信双方有各自的发送接收部件
        串口协议
            数据位是 5~8 位长
            -------+    +----+----+----+----+----+----+----+    +--------
                   |    |    |    |    |    |              |    |
                   |    |    |    |    |    |              |    |
                   +----+----+----+----+----+              +----+
            IDLE    SOF  DATA 0, 1...   PAR   EOF (2B) EMP  FIN   IDLE
        同步通信
            接受发送方时钟需要同步
            同步信号
                内 / 外: 同步字符 / 硬件同步信号

    USB
        IO设备可从USB上得到电源
            单台计算机最多连接 127 设备
            支持热插拔 i.e. 即插即用
        4根线:  GND, VCC, D+, D-
            VCC 和 GND 更长一点
            D+ D- 主要是为了抗干扰
        结构
            基于 hub 的主从结构
        设备检测
            存在一个根 hub, 其轮询查询接口状态
            对于所有设备赋值一个地址 (7位, 所以是127个设备)
            检测设备类型后, 操作系统和驱动负责管理和使用设备
            - 只有一个主设备, 不需要仲裁, 采用轮询, 适合低速
        USB 帧
            配置帧
            同步帧
            块 (bulk) 数据
            中断数据帧

    键盘
        通过阵列和串/并转换传输数据
        通过中断传输
        串行口 或者 并行口 传输数据

    鼠标
        机械 / 光电

******************************************************************************
rev
ALU
    - 数据表示:
        整数根据有无符号, 用 0/-2**31 整数环中的整数表示
            即 原/补码
        浮点数: 多种类型
        检错纠错码
            奇偶校验
            Hamming 校验
    - 运算
        - 减法实现: 加上整数环中负元
        - 乘法实现: 布斯算法
        - 除法: 列式, 即试商法
        - 关系算符: 标志位 Carry Zero oVerflow Sign
            用其逻辑函数来表示各种关系算符

CPU
    - 单周期
    - 多周期
        每条指令占用的指令周期数不同
        采用状态机设计
        - 硬连线
        - 微指令
    - 流水线
        冲突
            - control
            - data
        数据相关
            - stall
            - bubble
            - forwarding
            - branch pred.
            -* delay slot
            -* randomized execution

存储器
    物理实现
        - DRAM
        - SRAM
        - Disk
    层次存储结构
        - Cache
    虚拟存储空间
        地址映射

CP0 和操作系统协同

I/O 系统和设备

形式
    - 选择
    - 判断
    - 填空
    - 简答
    - 综合

`computer organization and design'
